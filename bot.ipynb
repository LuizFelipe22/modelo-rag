{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar bibliotecas\n",
    "\n",
    "- Necessário baixar o Ollama no computador: https://ollama.com/download\n",
    "- Após baixar o ollama, escreva o seguinte comando no terminal `ollama pull nomic-embed-text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"pymongo[srv]\"==3.12\n",
    "!pip install python-dotenv\n",
    "!pip install langchain-mongodb\n",
    "!pip install langchain-groq\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.mongodb.com/pt-br/docs/atlas/atlas-vector-search/ai-integrations/langchain/get-started/\n",
    "- https://www.mongodb.com/pt-br/docs/atlas/atlas-vector-search/ai-integrations/langchain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pymongo\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv('dev.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectar com o banco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acesse o arquivo `dev.env_exemplo`.\n",
    "- Inclua seus dados de conexão do mongoDB\n",
    "- Inclua a chave da API do grop\n",
    "- Renomear o nome do arquivo para `dev.env`\n",
    "\n",
    "- GROQ: https://console.groq.com/keys\n",
    "- MongoDB: https://cloud.mongodb.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USUARIO = getenv('USUARIO')\n",
    "SENHA = getenv('SENHA')\n",
    "NOME_CLUSTER = getenv('NOME_CLUSTER')\n",
    "HOSTNAME = getenv('HOSTNAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f\"mongodb+srv://{USUARIO}:{SENHA}@{NOME_CLUSTER}.{HOSTNAME}.mongodb.net\"\n",
    "\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Conexão estabelecida!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processar arquivo PDF\n",
    "\n",
    "- Usei um PDF de história como exemplo para processar o conteudo e enviar para o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_pdf = \"https://www.caesp.com.br/libwww/colegios/uploads/uploadsMateriais/07022023143038A-Historia-do-Mundo-Para-Quem-Tem-Pressa-by-Emma-Marriott-z-lib.org_.epub_.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(link_pdf)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processa os textos e cria embeddings de cada um\n",
    "\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "  connection_string = uri,\n",
    "  namespace = \"langchain_db.test\",\n",
    "  embedding = OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "  index_name = \"vector_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.create_vector_search_index(\n",
    "   dimensions = 768, # As dimensões dos embeddings vetoriais a serem indexados\n",
    "   filters = [ \"page_label\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo testes de pesquisa\n",
    "\n",
    "query = \"china antiga\"\n",
    "results = vector_store.similarity_search(query)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do RAG para pesquisar dados no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3-70b-8192\"\n",
    "model1 = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "llm = ChatGroq(model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuração do modelo para criar perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "   search_type = \"similarity\",\n",
    "   search_kwargs = { \"k\": 10,\n",
    "                     \"score_threshold\": 0.65 }\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "   Crie 1 questão de multipla escolha em português, com 5 opções de resposta. No final da questão coloque a alternativa correta. Essa questão deve ser criada com base no contexto a abaixo.\n",
    "   {contexto}\n",
    "   Topico: {topico}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "   { \"contexto\": retriever, \"topico\": RunnablePassthrough()}\n",
    "   | prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "questao = \"Estados Unidos\"\n",
    "answer = chain.invoke(questao)\n",
    "\n",
    "print(\"Questão: \" + questao)\n",
    "print(\"Resposta: \" + answer)\n",
    "\n",
    "\n",
    "documents = retriever.invoke(questao)\n",
    "print(\"\\nFonte dos documentos:\")\n",
    "pprint(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
